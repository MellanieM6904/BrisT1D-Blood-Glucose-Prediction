{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ea242-77e7-4994-933d-2055c74649c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team: Tethical Machine Learning\n",
    "# Team members: Mellanie Martin, Wyatt Pigeon, Koby Grah\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "class SelectColumns( BaseEstimator, TransformerMixin ):\n",
    "    def __init__( self, columns ):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit( self, xs, ys, **params ):\n",
    "        return self\n",
    "    \n",
    "    def transform( self, xs ):\n",
    "        return xs[ self.columns ]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv(\"Data/test.csv\")\n",
    "    cleanedData = pd.get_dummies(data, drop_first=True)\n",
    "    cleanedData = cleanedData.fillna(0)\n",
    "    bg = data.filter(like='bg').columns\n",
    "    cals = data.filter(like='cals').columns\n",
    "    insulin = data.filter(like='insulin').columns\n",
    "    regressor = TransformedTargetRegressor(\n",
    "        GradientBoostingRegressor(criterion = 'squared_error'),\n",
    "        func = np.sqrt,\n",
    "        inverse_func = np.square\n",
    "    )\n",
    "    steps = [\n",
    "        ('column_select', SelectColumns([bg, cals, insulin])),\n",
    "        ('gradientBoost', regressor ),\n",
    "    ]\n",
    "    pipe = Pipeline(steps)\n",
    "\n",
    "    grid = { \n",
    "        'column_select__columns': [\n",
    "            [bg, insulin, cals],\n",
    "        ],\n",
    "        'gradientBoost__loss': [\"squared_error\", \"absolute_error\"],\n",
    "        'gradientBoost__min_samples_split': range(2, 5),\n",
    "        'gradientBoost__max_depth': range(1, 10),\n",
    "        'gradient_boost': [\n",
    "        GradientBoostingRegressor(criterion = 'squared_error') # no transformation\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    search = GridSearchCV(pipe, grid, cv = 5, scoring = \"r2\", n_jobs = -1)\n",
    "    search.fit(xs, ys)\n",
    "    print(\"\\nGradient Boosting:\")\n",
    "    print(f\"R-squared: {search.best_score_}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb6e9a2-9614-4994-b467-ad19862cb761",
   "metadata": {},
   "source": [
    "Notes:\n",
    "1. Final predicted value is a float, so this is a regression problem\n",
    "2. Potential models to look at; Kernel Ridge, AdaBoost, Gradient Boosting\n",
    "3. Pipeline with minimum 3 stages is needed, and we need to use GridSearchCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_learning]",
   "language": "python",
   "name": "conda-env-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
